{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBvZfIhJO-Wc"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0\n",
        "\n",
        "Based on https://github.com/google-research/google-research/blob/master/revisiting_neural_scaling_laws/revisiting_neural_scaling_laws.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUTOFF = -1\n",
        "XMAX = -1\n",
        "SAVE_PATH = f\"./results/x{'org' if XMAX == -1 else XMAX}_cutoff{'org' if CUTOFF == -1 else CUTOFF}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D54H_RXGHwUG"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tgIZB6DGTWX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from methods import m1, m2, m3, m4\n",
        "from data.get_test_data import get_bench_data, get_DD_data, get_nano_data\n",
        "import os\n",
        "\n",
        "def get_error(slaw, x, y):\n",
        "  \"\"\"Evaluate the scaling law estimator slaw on the test data (x, y).\n",
        "\n",
        "  Args:\n",
        "    x: 1d array containing data sizes.\n",
        "    y: 1d array containing errors/losses.\n",
        "  \"\"\"\n",
        "  yp = np.array([slaw.predict_loss(xi) for xi in x])\n",
        "  error = (np.log(yp) - np.log(y)) ** 2\n",
        "  err_mu = np.mean(error)\n",
        "  err_std = np.sqrt(err_mu + np.std(error) / (len(yp)**0.5)) - np.sqrt(err_mu)\n",
        "  # return mean and std error\n",
        "  return np.sqrt(err_mu), err_std\n",
        "\n",
        "def create_dir(dir_name):\n",
        "  # if dir exists, remove it and its contents\n",
        "  try:\n",
        "    shutil.rmtree(dir_name)\n",
        "  except:\n",
        "    pass\n",
        "  os.mkdir(dir_name)\n",
        "\n",
        "np.random.seed(2021)\n",
        "\n",
        "scaling_laws = {}\n",
        "errors = {}\n",
        "\n",
        "M1 = m1.Estimator\n",
        "M2 = m2.Estimator\n",
        "M3 = m3.Estimator\n",
        "M4 = m4.Estimator\n",
        "\n",
        "# make directory to save the fitted parameters\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtDWqlDerDBr"
      },
      "source": [
        "## Load bench data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv5vqVaCitjb"
      },
      "outputs": [],
      "source": [
        "IC_data, NMT_data, LM_data, BB_data = get_bench_data('./data', cutoff=CUTOFF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PkGk5U4i2Dg"
      },
      "source": [
        "## Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IC_mode_params = {}\n",
        "IC_log = []\n",
        "os.makedirs(os.path.join(SAVE_PATH, 'IC'), exist_ok=True)\n",
        "for i, (key, xc, yc, xt, yt) in enumerate(IC_data):\n",
        "\tprint(f'Fitting {key} ({i+1}/{len(IC_data)})')\n",
        "\txc, yc, xt, yt = np.array(xc), np.array(yc), np.array(xt), np.array(yt)\n",
        "\tfit_values = {x: y for x, y in zip(xc, yc)}\n",
        "\n",
        "\tmode_params = {\n",
        "\t\t'M1': {},\n",
        "\t\t'M2': {},\n",
        "\t\t'M3': {},\n",
        "\t\t'M4': {},\n",
        "\t}\n",
        "\t\n",
        "\t# train all estimators\n",
        "\tscaling_laws[key] = {}\n",
        "\trmsle_list = []\n",
        "\tfor mode in ['M1', 'M2', 'M3', 'M4']:\n",
        "\t\tprint(mode)\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tscaling_laws[key][mode] = M1(fit_values)\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tscaling_laws[key][mode] = M2(fit_values)\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tscaling_laws[key][mode] = M3(fit_values)\n",
        "\t\telif mode == 'M4':\n",
        "\t\t\tscaling_laws[key][mode] = M4(fit_values, err_inf=None, err_0=1,\n",
        "\t\t\t\t\t\t\t\t\t\tupdate_err_0=True, up_bound=1.0)\n",
        "\t\t# fit\n",
        "\t\tscaling_laws[key][mode].estimate_scaling_params(verbose=0,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_iterations=10_000)\n",
        "\n",
        "\t\t# report\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tbeta, c = scaling_laws[key][mode].beta, scaling_laws[key][mode].c\n",
        "\t\t\tprint('beta, c =\\t\\t %.2f, %0.2f' % (beta, c))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tbeta, c, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, err_inf =\\t\\t %.2f, %0.2f, %0.2f' % (beta, c, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tbeta, c, gamma = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].gamma\n",
        "\t\t\tprint('beta, c, gamma =\\t\\t %.2f, %0.2f, %0.2f' %(beta, c, gamma))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['gamma']=gamma\n",
        "\t\telse:\n",
        "\t\t\tbeta, c, alpha, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].alpha, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, alpha, err_inf =\\t %.2f, %0.2f, %0.2f, %0.2f' %(beta, c, alpha, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['alpha']=alpha\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\n",
        "\t\t# record error\n",
        "\t\trmsle_mean, rmsle_std = get_error(scaling_laws[key][mode], xt, yt)\n",
        "\t\trmsle_mean, rmsle_std = rmsle_mean.item(), rmsle_std.item()\n",
        "\t\trmsle_list.append(rmsle_mean)\n",
        "\t\tprint('Extrapolation Loss =\\t\\t %.4f +- %.5f' %(rmsle_mean, rmsle_std))\n",
        "\t\tprint()\n",
        "\t\t\t\n",
        "\t\t# save plot\n",
        "\t\tx = np.concatenate([xc, xt])\n",
        "\t\typ = np.array([scaling_laws[key][mode].predict_loss(xi) for xi in x])\n",
        "\t\tplt.figure()\n",
        "\t\tplt.plot(xc, yc, color='black', label='context', marker='o')\n",
        "\t\tplt.plot(xt, yt, color=[0.0, 0.925, 0.0], label=\"target\", marker='o')\n",
        "\t\tplt.plot(x, yp, color='blue', label='pred')\n",
        "\t\tplt.vlines(max(xc), 0, 1.1, linewidth=0.5, color=\"k\", label=\"cutoff\", linestyle='--')\n",
        "\t\t\n",
        "\t\tplt.xscale(\"log\")\n",
        "\t\tplt.ylim(0, 1.1)\n",
        "\t\tplt.xlabel(\"Training Data Size\")\n",
        "\t\tplt.ylabel(\"Test Error Rate\")\n",
        "\t\t# show mode params in title with 3f precision\n",
        "\t\tplt.title(f\"{key} / {mode} / {rmsle_mean:.4f}\\n{', '.join([f'{k}={v:.3f}' for k, v in mode_params[mode].items()])}\")\n",
        "\t\tstr_key = ('_').join(key).replace('/', '_')\n",
        "\t\tplt.savefig(os.path.join(SAVE_PATH, 'IC', f'{str_key}_{mode}.png'))\n",
        "\t\tplt.show()\n",
        "\t\tplt.close()\n",
        "\tIC_mode_params[str(key)] = mode_params\n",
        "\tIC_log.append((*key, *rmsle_list))\n",
        "\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "errors = [item[3:7] for item in IC_log]  # Get elements 3 to 6 for each tuple\n",
        "IC_log.append(('IC', '', 'AVG', *[f'{avg:.4f}+-{std:.4f}' for avg, std in zip(np.mean(errors, axis=0), np.std(errors, axis=0))]))\n",
        "\n",
        "# change elemenet type from float32 to float\n",
        "for key in IC_mode_params:\n",
        "    for mode in IC_mode_params[key]:\n",
        "        for param in IC_mode_params[key][mode]:\n",
        "            IC_mode_params[key][mode][param] = float(IC_mode_params[key][mode][param])\n",
        "\n",
        "# Save the scaling law parameters as json'\n",
        "with open(f'{SAVE_PATH}/params_IC.json', 'w') as f:\n",
        "    json.dump(IC_mode_params, f, indent=4)\n",
        "\n",
        "# Save the errors as csv\n",
        "IC_df = pd.DataFrame(IC_log, columns=['domain', 'task', 'model', 'M1', 'M2', 'M3', 'M4'])\n",
        "IC_df.to_csv(os.path.join(SAVE_PATH, 'errors_IC.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPVFmQN3OHjm"
      },
      "source": [
        "## Neural Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd3-6CeaEgmt"
      },
      "outputs": [],
      "source": [
        "NMT_mode_params = {}\n",
        "NMT_log = []\n",
        "os.makedirs(os.path.join(SAVE_PATH, 'NMT'), exist_ok=True)\n",
        "for i, (key, xc, yc, xt, yt) in enumerate(NMT_data):\n",
        "\tprint(f'Fitting {key} ({i+1}/{len(NMT_data)})')\n",
        "\txc, yc, xt, yt = np.array(xc), np.array(yc), np.array(xt), np.array(yt)\n",
        "\tfit_values = {x: y for x, y in zip(xc, yc)}\n",
        "\n",
        "\tmode_params = {\n",
        "\t\t'M1': {},\n",
        "\t\t'M2': {},\n",
        "\t\t'M3': {},\n",
        "\t\t'M4': {},\n",
        "\t}\n",
        "\t\n",
        "\t# train all estimators\n",
        "\tscaling_laws[key] = {}\n",
        "\trmsle_list = []\n",
        "\tfor mode in ['M1', 'M2', 'M3', 'M4']:\n",
        "\t\tprint(mode)\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tscaling_laws[key][mode] = M1(fit_values)\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tscaling_laws[key][mode] = M2(fit_values)\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tscaling_laws[key][mode] = M3(fit_values)\n",
        "\t\telif mode == 'M4':\n",
        "\t\t\tscaling_laws[key][mode] = M4(fit_values, err_0=1.0, update_err_0=True,\n",
        "\t\t\t\t\t\t\t\t\t\t up_bound=None)  # no upper bound since this is log-preplexity\n",
        "\t\t# fit\n",
        "\t\tscaling_laws[key][mode].estimate_scaling_params(verbose=0,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_iterations=10_000)\n",
        "\n",
        "\t\t# report\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tbeta, c = scaling_laws[key][mode].beta, scaling_laws[key][mode].c\n",
        "\t\t\tprint('beta, c =\\t\\t %.2f, %0.2f' % (beta, c))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tbeta, c, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, err_inf =\\t\\t %.2f, %0.2f, %0.2f' % (beta, c, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tbeta, c, gamma = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].gamma\n",
        "\t\t\tprint('beta, c, gamma =\\t\\t %.2f, %0.2f, %0.2f' %(beta, c, gamma))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['gamma']=gamma\n",
        "\t\telse:\n",
        "\t\t\tbeta, c, alpha, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].alpha, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, alpha, err_inf =\\t %.2f, %0.2f, %0.2f, %0.2f' %(beta, c, alpha, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['alpha']=alpha\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\n",
        "\t\t# record error\n",
        "\t\trmsle_mean, rmsle_std = get_error(scaling_laws[key][mode], xt, yt)\n",
        "\t\trmsle_mean, rmsle_std = rmsle_mean.item(), rmsle_std.item()\n",
        "\t\trmsle_list.append(rmsle_mean)\n",
        "\t\tprint('Extrapolation Loss =\\t\\t %.4f +- %.5f' %(rmsle_mean, rmsle_std))\n",
        "\t\tprint()\n",
        "\t\t\t\n",
        "\t\t# save plot\n",
        "\t\tx = np.concatenate([xc, xt])\n",
        "\t\typ = np.array([scaling_laws[key][mode].predict_loss(xi) for xi in x])\n",
        "\t\tplt.figure()\n",
        "\t\tplt.plot(xc, yc, color='black', label='context', marker='o')\n",
        "\t\tplt.plot(xt, yt, color=[0.0, 0.925, 0.0], label=\"target\", marker='o')\n",
        "\t\tplt.plot(x, yp, color='blue', label='pred')\n",
        "\t\tplt.vlines(max(xc), 0, 1.1, linewidth=0.5, color=\"k\", label=\"cutoff\", linestyle='--')\n",
        "\t\t\n",
        "\t\tplt.xscale(\"log\")\n",
        "\t\tplt.ylim(0, 1.1)\n",
        "\t\tplt.xlabel(\"Training Data Size\")\n",
        "\t\tplt.ylabel(\"Test Error Rate\")\n",
        "\t\t# show mode params in title with 3f precision\n",
        "\t\tplt.title(f\"{key} / {mode} / {rmsle_mean:.4f}\\n{', '.join([f'{k}={v:.3f}' for k, v in mode_params[mode].items()])}\")\n",
        "\t\tstr_key = ('_').join(key).replace('/', '_')\n",
        "\t\tplt.savefig(os.path.join(SAVE_PATH, 'NMT', f'{str_key}_{mode}.png'))\n",
        "\t\tplt.show()\n",
        "\t\tplt.close()\n",
        "\tNMT_mode_params[str(key)] = mode_params\n",
        "\tNMT_log.append((*key, *rmsle_list))\n",
        "\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "errors = [item[3:7] for item in NMT_log]  # Get elements 3 to 6 for each tuple\n",
        "NMT_log.append(('NMT', '', 'AVG', *[f'{avg:.4f}+-{std:.4f}' for avg, std in zip(np.mean(errors, axis=0), np.std(errors, axis=0))]))\n",
        "\n",
        "# change elemenet type from float32 to float\n",
        "for key in NMT_mode_params:\n",
        "    for mode in NMT_mode_params[key]:\n",
        "        for param in NMT_mode_params[key][mode]:\n",
        "            NMT_mode_params[key][mode][param] = float(NMT_mode_params[key][mode][param])\n",
        "\n",
        "# Save the scaling law parameters as json'\n",
        "with open(f'{SAVE_PATH}/params_NMT.json', 'w') as f:\n",
        "    json.dump(NMT_mode_params, f, indent=4)\n",
        "\n",
        "# Save the errors as csv\n",
        "NMT_df = pd.DataFrame(NMT_log, columns=['domain', 'task', 'model', 'M1', 'M2', 'M3', 'M4'])\n",
        "NMT_df.to_csv(os.path.join(SAVE_PATH, 'errors_NMT.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciMRzpX1LbDb"
      },
      "source": [
        "## Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4XhGTysLnUg"
      },
      "outputs": [],
      "source": [
        "LM_mode_params = {}\n",
        "LM_log = []\n",
        "os.makedirs(os.path.join(SAVE_PATH, 'LM'), exist_ok=True)\n",
        "for i, (key, xc, yc, xt, yt) in enumerate(LM_data):\n",
        "\tprint(f'Fitting {key} ({i+1}/{len(LM_data)})')\n",
        "\txc, yc, xt, yt = np.array(xc), np.array(yc), np.array(xt), np.array(yt)\n",
        "\tfit_values = {x: y for x, y in zip(xc, yc)}\n",
        "\n",
        "\tmode_params = {\n",
        "\t\t'M1': {},\n",
        "\t\t'M2': {},\n",
        "\t\t'M3': {},\n",
        "\t\t'M4': {},\n",
        "\t}\n",
        "\t\n",
        "\t# train all estimators\n",
        "\tscaling_laws[key] = {}\n",
        "\trmsle_list = []\n",
        "\tfor mode in ['M1', 'M2', 'M3', 'M4']:\n",
        "\t\tprint(mode)\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tscaling_laws[key][mode] = M1(fit_values)\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tscaling_laws[key][mode] = M2(fit_values)\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tscaling_laws[key][mode] = M3(fit_values)\n",
        "\t\telif mode == 'M4':\n",
        "\t\t\tscaling_laws[key][mode] = M4(fit_values, err_0=1.0,\n",
        "\t\t\t\t\t\t\t\t\t\t update_err_0=True,\n",
        "\t\t\t\t\t\t\t\t\t\t up_bound=None)  # no upper bound since this is cross-entropy loss\n",
        "\t\t# fit\n",
        "\t\tscaling_laws[key][mode].estimate_scaling_params(verbose=0,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_iterations=10_000)\n",
        "\n",
        "\t\t# report\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tbeta, c = scaling_laws[key][mode].beta, scaling_laws[key][mode].c\n",
        "\t\t\tprint('beta, c =\\t\\t %.2f, %0.2f' % (beta, c))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tbeta, c, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, err_inf =\\t\\t %.2f, %0.2f, %0.2f' % (beta, c, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tbeta, c, gamma = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].gamma\n",
        "\t\t\tprint('beta, c, gamma =\\t\\t %.2f, %0.2f, %0.2f' %(beta, c, gamma))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['gamma']=gamma\n",
        "\t\telse:\n",
        "\t\t\tbeta, c, alpha, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].alpha, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, alpha, err_inf =\\t %.2f, %0.2f, %0.2f, %0.2f' %(beta, c, alpha, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['alpha']=alpha\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\n",
        "\t\t# record error\n",
        "\t\trmsle_mean, rmsle_std = get_error(scaling_laws[key][mode], xt, yt)\n",
        "\t\trmsle_mean, rmsle_std = rmsle_mean.item(), rmsle_std.item()\n",
        "\t\trmsle_list.append(rmsle_mean)\n",
        "\t\tprint('Extrapolation Loss =\\t\\t %.4f +- %.5f' %(rmsle_mean, rmsle_std))\n",
        "\t\tprint()\n",
        "\t\t\t\n",
        "\t\t# save plot\n",
        "\t\tx = np.concatenate([xc, xt])\n",
        "\t\typ = np.array([scaling_laws[key][mode].predict_loss(xi) for xi in x])\n",
        "\t\tplt.figure()\n",
        "\t\tplt.plot(xc, yc, color='black', label='context', marker='o')\n",
        "\t\tplt.plot(xt, yt, color=[0.0, 0.925, 0.0], label=\"target\", marker='o')\n",
        "\t\tplt.plot(x, yp, color='blue', label='pred')\n",
        "\t\tplt.vlines(max(xc), 0, 1.1, linewidth=0.5, color=\"k\", label=\"cutoff\", linestyle='--')\n",
        "\t\t\n",
        "\t\tplt.xscale(\"log\")\n",
        "\t\tplt.ylim(0, 1.1)\n",
        "\t\tplt.xlabel(\"Training Data Size\")\n",
        "\t\tplt.ylabel(\"Test Error Rate\")\n",
        "\t\t# show mode params in title with 3f precision\n",
        "\t\tplt.title(f\"{key} / {mode} / {rmsle_mean:.4f}\\n{', '.join([f'{k}={v:.3f}' for k, v in mode_params[mode].items()])}\")\n",
        "\t\tstr_key = ('_').join(key).replace('/', '_')\n",
        "\t\tplt.savefig(os.path.join(SAVE_PATH, 'LM', f'{str_key}_{mode}.png'))\n",
        "\t\tplt.show()\n",
        "\t\tplt.close()\n",
        "\tLM_mode_params[str(key)] = mode_params\n",
        "\tLM_log.append((*key, *rmsle_list))\n",
        "\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "errors = [item[3:7] for item in LM_log]  # Get elements 3 to 6 for each tuple\n",
        "LM_log.append(('LM', '', 'AVG', *[f'{avg:.4f}+-{std:.4f}' for avg, std in zip(np.mean(errors, axis=0), np.std(errors, axis=0))]))\n",
        "\n",
        "# change elemenet type from float32 to float\n",
        "for key in LM_mode_params:\n",
        "    for mode in LM_mode_params[key]:\n",
        "        for param in LM_mode_params[key][mode]:\n",
        "            LM_mode_params[key][mode][param] = float(LM_mode_params[key][mode][param])\n",
        "\n",
        "# Save the scaling law parameters as json'\n",
        "with open(f'{SAVE_PATH}/params_LM.json', 'w') as f:\n",
        "    json.dump(LM_mode_params, f, indent=4)\n",
        "\n",
        "# Save the errors as csv\n",
        "LM_df = pd.DataFrame(LM_log, columns=['domain', 'task', 'model', 'M1', 'M2', 'M3', 'M4'])\n",
        "LM_df.to_csv(os.path.join(SAVE_PATH, 'errors_LM.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6OD-eLgPVIN"
      },
      "source": [
        "## Big Bench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N4Lru7ABLRT"
      },
      "outputs": [],
      "source": [
        "BB_mode_params = {}\n",
        "BB_log = []\n",
        "os.makedirs(os.path.join(SAVE_PATH, 'BB'), exist_ok=True)\n",
        "for i, (key, xc, yc, xt, yt) in enumerate(BB_data):\n",
        "\tprint(f'Fitting {key} ({i+1}/{len(BB_data)})')\n",
        "\txc, yc, xt, yt = np.array(xc), np.array(yc), np.array(xt), np.array(yt)\n",
        "\tfit_values = {x: y for x, y in zip(xc, yc)}\n",
        "\n",
        "\tmode_params = {\n",
        "\t\t'M1': {},\n",
        "\t\t'M2': {},\n",
        "\t\t'M3': {},\n",
        "\t\t'M4': {},\n",
        "\t}\n",
        "\t\n",
        "\t# train all estimators\n",
        "\tscaling_laws[key] = {}\n",
        "\trmsle_list = []\n",
        "\tfor mode in ['M1', 'M2', 'M3', 'M4']:\n",
        "\t\tprint(mode)\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tscaling_laws[key][mode] = M1(fit_values)\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tscaling_laws[key][mode] = M2(fit_values)\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tscaling_laws[key][mode] = M3(fit_values)\n",
        "\t\telif mode == 'M4':\n",
        "\t\t\tscaling_laws[key][mode] = M4(fit_values, err_inf=None, err_0=1.001,\n",
        "\t\t\t\t\t\t\t\t\t\tupdate_err_0=True, up_bound=1.0)\n",
        "\t\t# fit\n",
        "\t\tscaling_laws[key][mode].estimate_scaling_params(verbose=0,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_iterations=10_000)\n",
        "\n",
        "\t\t# report\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tbeta, c = scaling_laws[key][mode].beta, scaling_laws[key][mode].c\n",
        "\t\t\tprint('beta, c =\\t\\t %.2f, %0.2f' % (beta, c))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tbeta, c, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, err_inf =\\t\\t %.2f, %0.2f, %0.2f' % (beta, c, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tbeta, c, gamma = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].gamma\n",
        "\t\t\tprint('beta, c, gamma =\\t\\t %.2f, %0.2f, %0.2f' %(beta, c, gamma))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['gamma']=gamma\n",
        "\t\telse:\n",
        "\t\t\tbeta, c, alpha, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].alpha, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, alpha, err_inf =\\t %.2f, %0.2f, %0.2f, %0.2f' %(beta, c, alpha, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['alpha']=alpha\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\n",
        "\t\t# record error\n",
        "\t\trmsle_mean, rmsle_std = get_error(scaling_laws[key][mode], xt, yt)\n",
        "\t\trmsle_mean, rmsle_std = rmsle_mean.item(), rmsle_std.item()\n",
        "\t\trmsle_list.append(rmsle_mean)\n",
        "\t\tprint('Extrapolation Loss =\\t\\t %.4f +- %.5f' %(rmsle_mean, rmsle_std))\n",
        "\t\tprint()\n",
        "\t\t\t\n",
        "\t\t# save plot\n",
        "\t\tx = np.concatenate([xc, xt])\n",
        "\t\typ = np.array([scaling_laws[key][mode].predict_loss(xi) for xi in x])\n",
        "\t\tplt.figure()\n",
        "\t\tplt.plot(xc, yc, color='black', label='context', marker='o')\n",
        "\t\tplt.plot(xt, yt, color=[0.0, 0.925, 0.0], label=\"target\", marker='o')\n",
        "\t\tplt.plot(x, yp, color='blue', label='pred')\n",
        "\t\tplt.vlines(max(xc), 0, 1.1, linewidth=0.5, color=\"k\", label=\"cutoff\", linestyle='--')\n",
        "\t\t\n",
        "\t\tplt.xscale(\"log\")\n",
        "\t\tplt.ylim(0, 1.1)\n",
        "\t\tplt.xlabel(\"Training Data Size\")\n",
        "\t\tplt.ylabel(\"Test Error Rate\")\n",
        "\t\t# show mode params in title with 3f precision\n",
        "\t\tplt.title(f\"{key} / {mode} / {rmsle_mean:.4f}\\n{', '.join([f'{k}={v:.3f}' for k, v in mode_params[mode].items()])}\")\n",
        "\t\tstr_key = ('_').join(key).replace('/', '_')\n",
        "\t\tplt.savefig(os.path.join(SAVE_PATH, 'BB', f'{str_key}_{mode}.png'))\n",
        "\t\tplt.show()\n",
        "\t\tplt.close()\n",
        "\tBB_mode_params[str(key)] = mode_params\n",
        "\tBB_log.append((*key, *rmsle_list))\n",
        "\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "errors = [item[3:7] for item in BB_log]  # Get elements 3 to 6 for each tuple\n",
        "BB_log.append(('BB', '', 'AVG', *[f'{avg:.4f}+-{std:.4f}' for avg, std in zip(np.mean(errors, axis=0), np.std(errors, axis=0))]))\n",
        "\n",
        "# change elemenet type from float32 to float\n",
        "for key in BB_mode_params:\n",
        "    for mode in BB_mode_params[key]:\n",
        "        for param in BB_mode_params[key][mode]:\n",
        "            BB_mode_params[key][mode][param] = float(BB_mode_params[key][mode][param])\n",
        "\n",
        "# Save the scaling law parameters as json'\n",
        "with open(f'{SAVE_PATH}/params_BB.json', 'w') as f:\n",
        "    json.dump(BB_mode_params, f, indent=4)\n",
        "\n",
        "# Save the errors as csv\n",
        "BB_df = pd.DataFrame(BB_log, columns=['domain', 'task', 'model', 'M1', 'M2', 'M3', 'M4'])\n",
        "BB_df.to_csv(os.path.join(SAVE_PATH, 'errors_BB.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Double Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DD_data, DD_labels = get_DD_data('./data', cutoff=CUTOFF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DD_mode_params = {}\n",
        "DD_log = []\n",
        "os.makedirs(os.path.join(SAVE_PATH, 'DD'), exist_ok=True)\n",
        "for i, (key, xc, yc, xt, yt) in enumerate(DD_data):\n",
        "\ttask = key[1]\n",
        "\tprint(f'Fitting {task} ({i+1}/{len(DD_data)})')\n",
        "\txc, yc, xt, yt = np.array(xc), np.array(yc), np.array(xt), np.array(yt)\n",
        "\n",
        "\ty_max = max(np.max(yc), np.max(yt))\n",
        "\tyc_norm = yc / y_max\n",
        "\tyt_norm = yt / y_max\n",
        "\n",
        "\tfit_values = {x: y for x, y in zip(xc, yc_norm)}\n",
        "\n",
        "\tmode_params = {\n",
        "\t\t'M1': {},\n",
        "\t\t'M2': {},\n",
        "\t\t'M3': {},\n",
        "\t\t'M4': {},\n",
        "\t}\n",
        "\t\n",
        "\t# train all estimators\n",
        "\tscaling_laws[key] = {}\n",
        "\trmsle_list = []\n",
        "\tfor mode in ['M1', 'M2', 'M3', 'M4']:\n",
        "\t\tprint(mode)\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tscaling_laws[key][mode] = M1(fit_values)\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tscaling_laws[key][mode] = M2(fit_values)\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tscaling_laws[key][mode] = M3(fit_values)#, use_epsilon=True)\n",
        "\t\telif mode == 'M4':\n",
        "\t\t\tscaling_laws[key][mode] = M4(fit_values, err_inf=None, err_0=1.001,\n",
        "\t\t\t\t\t\t\t\t\t\tupdate_err_0=True, up_bound=1.0)\n",
        "\t\t# fit\n",
        "\t\tscaling_laws[key][mode].estimate_scaling_params(verbose=0,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_iterations=10_000)\n",
        "\n",
        "\t\t# report\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tbeta, c = scaling_laws[key][mode].beta, scaling_laws[key][mode].c\n",
        "\t\t\tprint('beta, c =\\t\\t %.2f, %0.2f' % (beta, c))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tbeta, c, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, err_inf =\\t\\t %.2f, %0.2f, %0.2f' % (beta, c, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tbeta, c, gamma = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].gamma\n",
        "\t\t\tprint('beta, c, gamma =\\t\\t %.2f, %0.2f, %0.2f' %(beta, c, gamma))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['gamma']=gamma\n",
        "\t\telse:\n",
        "\t\t\tbeta, c, alpha, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].alpha, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, alpha, err_inf =\\t %.2f, %0.2f, %0.2f, %0.2f' %(beta, c, alpha, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['alpha']=alpha\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\n",
        "\t\t# record error\n",
        "\t\trmsle_mean, rmsle_std = get_error(scaling_laws[key][mode], xt, yt)\n",
        "\t\trmsle_mean, rmsle_std = rmsle_mean.item(), rmsle_std.item()\n",
        "\t\trmsle_list.append(rmsle_mean)\n",
        "\t\tprint('Extrapolation Loss =\\t\\t %.4f +- %.5f' %(rmsle_mean, rmsle_std))\n",
        "\t\tprint()\n",
        "\t\t\t\n",
        "\t\t# save plot\n",
        "\t\tx = np.concatenate([xc, xt])\n",
        "\t\typ = np.array([scaling_laws[key][mode].predict_loss(xi) for xi in x])\n",
        "\t\typ_unnorm = yp * y_max\n",
        "\t\tx_min, x_max, y_min, y_max = min(xc.min().item(), xt.min().item()), max(xc.max().item(), xt.max().item()), min(yc.min().item(), yt.min().item()), max(yc.max().item(), yt.max().item())\n",
        "\t\t\n",
        "\t\tplt.figure()\n",
        "\t\tplt.plot(xc, yc, color='black', label='context', marker='o')\n",
        "\t\tplt.plot(xt, yt, color=[0.0, 0.925, 0.0], label=\"target\", marker='o')\n",
        "\t\tplt.plot(x, yp_unnorm, color='blue', label='pred')\n",
        "\t\tplt.vlines(max(xc), y_min*.9, y_max*1.05, linewidth=0.5, color=\"k\", label=\"cutoff\", linestyle='--')\n",
        "\t\tplt.xlim(x_min*.865,x_max*1.05)\n",
        "\t\tplt.ylim(y_min*.9, y_max*1.05)\n",
        "\t\tx_label, y_label = DD_labels[task]\n",
        "\t\tplt.xlabel(x_label)\n",
        "\t\tplt.ylabel(y_label)\n",
        "\t\t# show mode params in title with 3f precision\n",
        "\t\tplt.title(f\"{key} / {mode} / {rmsle_mean:.4f}\\n{', '.join([f'{k}={v:.3f}' for k, v in mode_params[mode].items()])}\")\n",
        "\t\tplt.savefig(os.path.join(SAVE_PATH, 'DD', f'{task}_{mode}.png'))\n",
        "\t\tplt.show()\n",
        "\t\tplt.close()\n",
        "\tDD_mode_params[str(key)] = mode_params\n",
        "\tDD_log.append((*key, *rmsle_list))\n",
        "\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "errors = [item[3:7] for item in DD_log]  # Get elements 3 to 6 for each tuple\n",
        "DD_log.append(('DD', '', 'AVG', *[f'{avg:.4f}+-{std:.4f}' for avg, std in zip(np.mean(errors, axis=0), np.std(errors, axis=0))]))\n",
        "\n",
        "# change elemenet type from float32 to float\n",
        "for key in DD_mode_params:\n",
        "    for mode in DD_mode_params[key]:\n",
        "        for param in DD_mode_params[key][mode]:\n",
        "            DD_mode_params[key][mode][param] = float(DD_mode_params[key][mode][param])\n",
        "\n",
        "# Save the scaling law parameters as json'\n",
        "with open(f'{SAVE_PATH}/params_DD.json', 'w') as f:\n",
        "    json.dump(DD_mode_params, f, indent=4)\n",
        "\n",
        "# Save the errors as csv\n",
        "DD_df = pd.DataFrame(DD_log, columns=['domain', 'task', 'model', 'M1', 'M2', 'M3', 'M4'])\n",
        "DD_df.to_csv(os.path.join(SAVE_PATH, 'errors_DD.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nano_data = get_nano_data('./data', cutoff=CUTOFF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nano_mode_params = {}\n",
        "nano_log = []\n",
        "os.makedirs(os.path.join(SAVE_PATH, 'Nano'), exist_ok=True)\n",
        "for i, (key, xc, yc, xt, yt) in enumerate(nano_data):\n",
        "\ttask = key[1]\n",
        "\tprint(f'Fitting {task} ({i+1}/{len(nano_data)})')\n",
        "\txc, yc, xt, yt = np.array(xc), np.array(yc), np.array(xt), np.array(yt)\n",
        "\n",
        "\ty_max = max(np.max(yc), np.max(yt))\n",
        "\tyc_norm = yc / y_max\n",
        "\tyt_norm = yt / y_max\n",
        "\n",
        "\tfit_values = {x: y for x, y in zip(xc, yc_norm)}\n",
        "\n",
        "\tmode_params = {\n",
        "\t\t'M1': {},\n",
        "\t\t'M2': {},\n",
        "\t\t'M3': {},\n",
        "\t\t'M4': {},\n",
        "\t}\n",
        "\t\n",
        "\t# train all estimators\n",
        "\tscaling_laws[key] = {}\n",
        "\trmsle_list = []\n",
        "\tfor mode in ['M1', 'M2', 'M3', 'M4']:\n",
        "\t\tprint(mode)\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tscaling_laws[key][mode] = M1(fit_values)\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tscaling_laws[key][mode] = M2(fit_values)\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tscaling_laws[key][mode] = M3(fit_values)#, use_epsilon=True)\n",
        "\t\telif mode == 'M4':\n",
        "\t\t\tscaling_laws[key][mode] = M4(fit_values, err_inf=None, err_0=1.001,\n",
        "\t\t\t\t\t\t\t\t\t\tupdate_err_0=True, up_bound=1.0)\n",
        "\t\t# fit\n",
        "\t\tscaling_laws[key][mode].estimate_scaling_params(verbose=0,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tmax_iterations=10_000)\n",
        "\n",
        "\t\t# report\n",
        "\t\tif mode == 'M1':\n",
        "\t\t\tbeta, c = scaling_laws[key][mode].beta, scaling_laws[key][mode].c\n",
        "\t\t\tprint('beta, c =\\t\\t %.2f, %0.2f' % (beta, c))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\telif mode == 'M2':\n",
        "\t\t\tbeta, c, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, err_inf =\\t\\t %.2f, %0.2f, %0.2f' % (beta, c, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\t\telif mode == 'M3':\n",
        "\t\t\tbeta, c, gamma = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].gamma\n",
        "\t\t\tprint('beta, c, gamma =\\t\\t %.2f, %0.2f, %0.2f' %(beta, c, gamma))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['gamma']=gamma\n",
        "\t\telse:\n",
        "\t\t\tbeta, c, alpha, err_inf = scaling_laws[key][mode].beta, scaling_laws[key][mode].c, scaling_laws[key][mode].alpha, scaling_laws[key][mode].err_inf\n",
        "\t\t\tprint('beta, c, alpha, err_inf =\\t %.2f, %0.2f, %0.2f, %0.2f' %(beta, c, alpha, err_inf))\n",
        "\t\t\tmode_params[mode]['beta']=beta\n",
        "\t\t\tmode_params[mode]['c']=c\n",
        "\t\t\tmode_params[mode]['alpha']=alpha\n",
        "\t\t\tmode_params[mode]['err_inf']=err_inf\n",
        "\n",
        "\t\t# record error\n",
        "\t\trmsle_mean, rmsle_std = get_error(scaling_laws[key][mode], xt, yt)\n",
        "\t\trmsle_mean, rmsle_std = rmsle_mean.item(), rmsle_std.item()\n",
        "\t\trmsle_list.append(rmsle_mean)\n",
        "\t\tprint('Extrapolation Loss =\\t\\t %.4f +- %.5f' %(rmsle_mean, rmsle_std))\n",
        "\t\tprint()\n",
        "\t\t\t\n",
        "\t\t# save plot\n",
        "\t\tx = np.concatenate([xc, xt])\n",
        "\t\typ = np.array([scaling_laws[key][mode].predict_loss(xi) for xi in x])\n",
        "\t\typ_unnorm = yp * y_max\n",
        "\t\tx_min, x_max, y_min, y_max = min(xc.min().item(), xt.min().item()), max(xc.max().item(), xt.max().item()), min(yc.min().item(), yt.min().item()), max(yc.max().item(), yt.max().item())\n",
        "\t\t\n",
        "\t\tplt.figure()\n",
        "\t\tplt.plot(xc, yc, color='black', label='context', marker='o')\n",
        "\t\tplt.plot(xt, yt, color=[0.0, 0.925, 0.0], label=\"target\", marker='o')\n",
        "\t\tplt.plot(x, yp_unnorm, color='blue', label='pred')\n",
        "\t\tplt.vlines(max(xc), y_min*.9, y_max*1.05, linewidth=0.5, color=\"k\", label=\"cutoff\", linestyle='--')\n",
        "\t\tplt.xscale(\"log\")\n",
        "\t\tplt.xlim(x_min*.865,x_max*1.05)\n",
        "\t\tplt.ylim(y_min*.9, y_max*1.05)\n",
        "\t\tplt.xlabel('n_embed')\n",
        "\t\tplt.ylabel('val_loss')\n",
        "\t\t# show mode params in title with 3f precision\n",
        "\t\tplt.title(f\"{key} / {mode} / {rmsle_mean:.4f}\\n{', '.join([f'{k}={v:.3f}' for k, v in mode_params[mode].items()])}\")\n",
        "\t\tplt.savefig(os.path.join(SAVE_PATH, 'Nano', f'{task}_{mode}.png'))\n",
        "\t\tplt.show()\n",
        "\t\tplt.close()\n",
        "\tnano_mode_params[str(key)] = mode_params\n",
        "\tnano_log.append((*key, *rmsle_list))\n",
        "\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "errors = [item[3:7] for item in nano_log]  # Get elements 3 to 6 for each tuple\n",
        "nano_log.append(('nano', '', 'AVG', *[f'{avg:.4f}+-{std:.4f}' for avg, std in zip(np.mean(errors, axis=0), np.std(errors, axis=0))]))\n",
        "\n",
        "# change elemenet type from float32 to float\n",
        "for key in nano_mode_params:\n",
        "    for mode in nano_mode_params[key]:\n",
        "        for param in nano_mode_params[key][mode]:\n",
        "            nano_mode_params[key][mode][param] = float(nano_mode_params[key][mode][param])\n",
        "\n",
        "# Save the scaling law parameters as json'\n",
        "with open(f'{SAVE_PATH}/params_nano.json', 'w') as f:\n",
        "    json.dump(nano_mode_params, f, indent=4)\n",
        "\n",
        "# Save the errors as csv\n",
        "nano_df = pd.DataFrame(nano_log, columns=['domain', 'task', 'model', 'M1', 'M2', 'M3', 'M4'])\n",
        "nano_df.to_csv(os.path.join(SAVE_PATH, 'errors_nano.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merge df and save\n",
        "dataframes = [IC_df, BB_df, LM_df, NMT_df, DD_df, nano_df]\n",
        "\n",
        "# Separate main parts and last rows\n",
        "main_parts = [df.iloc[:-1] for df in dataframes]  # Exclude the last row of each dataframe\n",
        "last_rows = [df.iloc[-1:] for df in dataframes]   # Only the last row of each dataframe\n",
        "\n",
        "# Concatenate main parts and last rows\n",
        "merged_df = pd.concat(main_parts, ignore_index=True)    # Merge main parts first\n",
        "merged_df = pd.concat([merged_df] + last_rows, ignore_index=True)  # Add last rows at the end\n",
        "\n",
        "# Save to a file\n",
        "merged_df.to_csv(os.path.join(SAVE_PATH, \"errors.csv\" if CUTOFF == -1 else f\"error_cutoff{CUTOFF}.csv\"), index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "revisiting_neural_scaling_laws.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
